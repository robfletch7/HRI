{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('final_dataset_3.csv')\n",
    "dataset = dataset.set_index('Unnamed: 0')\n",
    "drop_columns = ['eda_time','form_time', 'gender']\n",
    "dataset.drop(drop_columns, axis=1, inplace=True)\n",
    "dataset = dataset.rename(columns={\"perc_change\": \"eda_perc_change\", \"abs_change\": \"eda_abs_change\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JUNEGO~1\\AppData\\Local\\Temp/ipykernel_3716/2732412840.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_dataset_SE[final_dataset_SE == -1] = 0\n",
      "C:\\Users\\junegoo94\\miniconda3\\envs\\comp0084\\lib\\site-packages\\pandas\\core\\frame.py:3718: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._where(-key, value, inplace=True)\n",
      "C:\\Users\\JUNEGO~1\\AppData\\Local\\Temp/ipykernel_3716/2732412840.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_dataset_SE['eda_perc_change'] = final_dataset_SE['eda_perc_change']/100 +1\n",
      "C:\\Users\\JUNEGO~1\\AppData\\Local\\Temp/ipykernel_3716/2732412840.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_dataset_A[final_dataset_SE == -1] = 0\n",
      "C:\\Users\\JUNEGO~1\\AppData\\Local\\Temp/ipykernel_3716/2732412840.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_dataset_A['eda_perc_change'] = final_dataset_A['eda_perc_change']/100 +1\n",
      "C:\\Users\\JUNEGO~1\\AppData\\Local\\Temp/ipykernel_3716/2732412840.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_dataset_F[final_dataset_F == -1] = 0\n",
      "C:\\Users\\JUNEGO~1\\AppData\\Local\\Temp/ipykernel_3716/2732412840.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_dataset_F['eda_perc_change'] = final_dataset_F['eda_perc_change']/100 +1\n"
     ]
    }
   ],
   "source": [
    "perc_columns = [col for col in dataset.columns if 'perc' in col]\n",
    "dataset_perc = df = dataset[dataset.columns.drop(list(dataset.filter(regex='abs')))]\n",
    "\n",
    "# columns = ['eda_perc_change','participantID', 'change_in_stressed', 'change_in_amused','change_in_engaged','change_in_frustrated']\n",
    "total_x_feature_lst = dataset_perc.columns.tolist()[:14]\n",
    "x_feature_lst_SE =  ['eda_perc_change','perc_bpm','perc_rmssd','perc_sdsd'] # stressed, engaged\n",
    "x_feature_lst_A =  ['eda_perc_change','perc_s', 'perc_breathingrate'] # amused\n",
    "x_feature_lst_F =  ['eda_perc_change','perc_bpm'] # frustrated\n",
    "\n",
    "participantID = ['participantID']\n",
    "y_labels = ['change_in_stressed', 'change_in_amused','change_in_engaged','change_in_frustrated']\n",
    "corresponding_x_features = [x_feature_lst_SE, x_feature_lst_A, x_feature_lst_SE, x_feature_lst_F]\n",
    "\n",
    "columns_SE = x_feature_lst_SE + participantID + y_labels\n",
    "columns_A = x_feature_lst_A + participantID + y_labels\n",
    "columns_F = x_feature_lst_F + participantID + y_labels\n",
    "\n",
    "final_dataset_SE = dataset_perc[columns_SE]\n",
    "final_dataset_SE[final_dataset_SE == -1] = 0\n",
    "final_dataset_SE['eda_perc_change'] = final_dataset_SE['eda_perc_change']/100 +1\n",
    "\n",
    "final_dataset_A = dataset_perc[columns_A]\n",
    "final_dataset_A[final_dataset_SE == -1] = 0\n",
    "final_dataset_A['eda_perc_change'] = final_dataset_A['eda_perc_change']/100 +1\n",
    "\n",
    "final_dataset_F = dataset_perc[columns_F]\n",
    "final_dataset_F[final_dataset_F == -1] = 0\n",
    "final_dataset_F['eda_perc_change'] = final_dataset_F['eda_perc_change']/100 +1\n",
    "\n",
    "corresponding_datasets = [final_dataset_SE, final_dataset_A,final_dataset_SE, final_dataset_F]\n",
    "\n",
    "\n",
    "svm = SVC(kernel='linear')\n",
    "dt = DecisionTreeClassifier(random_state=0)\n",
    "rt = RandomForestClassifier(n_estimators = 10,max_depth=2, random_state=0,min_samples_leaf=1)\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "\n",
    "models_lst = [svm, dt, rt, knn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Models\n",
      "\n",
      "Stressed & Engaged\n",
      "                      eda_perc_change  perc_bpm  perc_rmssd  perc_sdsd\n",
      "change_in_stressed                0.0       1.0         2.0        1.0\n",
      "change_in_amused                  2.0       1.0         1.0        1.0\n",
      "change_in_engaged                 0.0       1.0         0.0        0.0\n",
      "change_in_frustrated              0.0       1.0         1.0        3.0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Amused\n",
      "                      eda_perc_change  perc_s  perc_breathingrate\n",
      "change_in_stressed                0.0     0.0                 3.0\n",
      "change_in_amused                  2.0     0.0                 1.0\n",
      "change_in_engaged                 0.0     0.0                 2.0\n",
      "change_in_frustrated              0.0     3.0                 0.0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Frustrated\n",
      "                      eda_perc_change  perc_bpm\n",
      "change_in_stressed                0.0       1.0\n",
      "change_in_amused                  2.0       1.0\n",
      "change_in_engaged                 0.0       1.0\n",
      "change_in_frustrated              0.0       1.0\n"
     ]
    }
   ],
   "source": [
    "# Model selection\n",
    "def model_selection(x_feature_lst, final_dataset):\n",
    "    label_feature_model = np.zeros((len(y_labels),len(x_feature_lst)))\n",
    "\n",
    "    for label_id in range(len(y_labels)):\n",
    "        for feature_id in range(len(x_feature_lst)):\n",
    "            results_acc = []\n",
    "\n",
    "            for model in models_lst:\n",
    "                clf = model\n",
    "                participantIDs = np.arange(11)\n",
    "                # Start Cross-Validation\n",
    "                for i, a in enumerate(participantIDs):\n",
    "                    train_ids = participantIDs[participantIDs!=i]\n",
    "                    test_ids = participantIDs[participantIDs==i]\n",
    "                    train_data = final_dataset.loc[final_dataset['participantID'].isin(train_ids)]\n",
    "                    test_data = final_dataset.loc[final_dataset['participantID'].isin(test_ids)]\n",
    "\n",
    "\n",
    "                    x_train = np.array(train_data[x_feature_lst[feature_id]].values).reshape(-1, 1)\n",
    "                    y_train = np.array(train_data[y_labels[label_id]].values)\n",
    "                    x_test = np.array(test_data[x_feature_lst[feature_id]].values).reshape(-1, 1)\n",
    "                    y_test = np.array(test_data[y_labels[label_id]].values)\n",
    "\n",
    "                    clf.fit(x_train, y_train)\n",
    "                    predict = clf.predict(x_test)\n",
    "\n",
    "                    if i == 0:\n",
    "                        predictions = predict\n",
    "                    else:\n",
    "                        predictions = np.concatenate([predictions, predict])\n",
    "\n",
    "\n",
    "                results_acc.append(accuracy_score(predictions, final_dataset[y_labels[2]].values))\n",
    "\n",
    "            best_model_ind = np.argmax(results_acc)\n",
    "            label_feature_model[label_id, feature_id] = best_model_ind\n",
    "    return label_feature_model\n",
    "\n",
    "# 0.0 -> svm, 1.0 -> dt, 2.0 -> rf, 3.0 -> knn\n",
    "SE_label_feature_model = model_selection(x_feature_lst_SE, final_dataset_SE)\n",
    "pd_SE_label_feature_model = pd.DataFrame(SE_label_feature_model,\n",
    "                  index=y_labels, columns=x_feature_lst_SE)\n",
    "\n",
    "A_label_feature_model = model_selection(x_feature_lst_A, final_dataset_A)\n",
    "pd_A_label_feature_model = pd.DataFrame(A_label_feature_model,\n",
    "                  index=y_labels, columns=x_feature_lst_A)\n",
    "\n",
    "F_label_feature_model = model_selection(x_feature_lst_F, final_dataset_F)\n",
    "pd_F_label_feature_model = pd.DataFrame(F_label_feature_model,\n",
    "                  index=y_labels, columns=x_feature_lst_F)\n",
    "\n",
    "corresponding_models = [SE_label_feature_model, A_label_feature_model, SE_label_feature_model, F_label_feature_model]\n",
    "\n",
    "print('Selected Models')\n",
    "print()\n",
    "print('Stressed & Engaged')\n",
    "print(pd_SE_label_feature_model)\n",
    "print('-' * 100)\n",
    "print('Amused')\n",
    "print(pd_A_label_feature_model)\n",
    "print('-' * 100)\n",
    "print('Frustrated')\n",
    "print(pd_F_label_feature_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "label name: change_in_stressed\n",
      "\n",
      "TRAIN - # of 0 and 1 of Ground Truth // 0: 60     1: 110\n",
      "TRAIN - # of 0 and 1 correctly predict // 0: 48     1: 110\n",
      "TRAIN -  0.8 // 1.0\n",
      "\n",
      "TEST - # of 0 and 1 of Ground Truth // 0: 5     1: 11\n",
      "TEST - # of 0 and 1 correctly predict // 0: 2     1: 10\n",
      "TEST -  0.4 // 0.91\n",
      "BASELINE ACCURACY 0.65\n",
      "Total Train Accuracy: 0.93\n",
      "Total Test Accuracy: 0.75\n",
      "\n",
      "Confusion Matrix -  change_in_stressed\n",
      "[[ 2  1]\n",
      " [ 3 10]]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "label name: change_in_amused\n",
      "\n",
      "TRAIN - # of 0 and 1 of Ground Truth // 0: 70     1: 100\n",
      "TRAIN - # of 0 and 1 correctly predict // 0: 65     1: 99\n",
      "TRAIN -  0.93 // 0.99\n",
      "\n",
      "TEST - # of 0 and 1 of Ground Truth // 0: 6     1: 10\n",
      "TEST - # of 0 and 1 correctly predict // 0: 1     1: 8\n",
      "TEST -  0.17 // 0.8\n",
      "BASELINE ACCURACY 0.59\n",
      "Total Train Accuracy: 0.96\n",
      "Total Test Accuracy: 0.56\n",
      "\n",
      "Confusion Matrix -  change_in_amused\n",
      "[[1 2]\n",
      " [5 8]]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "label name: change_in_engaged\n",
      "\n",
      "TRAIN - # of 0 and 1 of Ground Truth // 0: 90     1: 80\n",
      "TRAIN - # of 0 and 1 correctly predict // 0: 61     1: 61\n",
      "TRAIN -  0.68 // 0.76\n",
      "\n",
      "TEST - # of 0 and 1 of Ground Truth // 0: 8     1: 8\n",
      "TEST - # of 0 and 1 correctly predict // 0: 7     1: 6\n",
      "TEST -  0.88 // 0.75\n",
      "BASELINE ACCURACY 0.47\n",
      "Total Train Accuracy: 0.72\n",
      "Total Test Accuracy: 0.81\n",
      "\n",
      "Confusion Matrix -  change_in_engaged\n",
      "[[7 2]\n",
      " [1 6]]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "label name: change_in_frustrated\n",
      "\n",
      "TRAIN - # of 0 and 1 of Ground Truth // 0: 110     1: 60\n",
      "TRAIN - # of 0 and 1 correctly predict // 0: 110     1: 34\n",
      "TRAIN -  1.0 // 0.57\n",
      "\n",
      "TEST - # of 0 and 1 of Ground Truth // 0: 10     1: 6\n",
      "TEST - # of 0 and 1 correctly predict // 0: 9     1: 1\n",
      "TEST -  0.9 // 0.17\n",
      "BASELINE ACCURACY 0.65\n",
      "Total Train Accuracy: 0.85\n",
      "Total Test Accuracy: 0.62\n",
      "\n",
      "Confusion Matrix -  change_in_frustrated\n",
      "[[9 5]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "def label_predictions(y_label, x_feature_lst, final_dataset, models):\n",
    "    '''\n",
    "    - Description:\n",
    "        returns final voting predictions for one label (ex: change_in_stressed)\n",
    "    - returns:\n",
    "        total_predictions - > (selected models, prediction(data))\n",
    "        final_voting -> (1, voting prediction)\n",
    "    '''\n",
    "\n",
    "    total_predictions = np.zeros((len(x_feature_lst), len(final_dataset)))\n",
    "    total_train_predictions = np.zeros((len(x_feature_lst), 170))\n",
    "    train_gt = np.zeros(170)\n",
    "\n",
    "    participantIDs = np.arange(11)\n",
    "    # Start Cross-Validation\n",
    "    test_data_length = 0\n",
    "    train_data_length = 0\n",
    "    for i, a in enumerate(participantIDs):\n",
    "        for feature_id in range(len(x_feature_lst)):\n",
    "            train_ids = participantIDs[participantIDs!=i]\n",
    "            test_ids = participantIDs[participantIDs==i]\n",
    "            train_data = final_dataset.loc[final_dataset['participantID'].isin(train_ids)]\n",
    "            test_data = final_dataset.loc[final_dataset['participantID'].isin(test_ids)]\n",
    "            x_train = np.array(train_data[x_feature_lst[feature_id]].values).reshape(-1, 1)\n",
    "            y_train = np.array(train_data[y_label].values)\n",
    "            x_test = np.array(test_data[x_feature_lst[feature_id]].values).reshape(-1, 1)\n",
    "            y_test = np.array(test_data[y_label].values)\n",
    "\n",
    "            model_ind = models[y_labels.index(y_label), feature_id]\n",
    "            clf = models_lst[int(model_ind)]\n",
    "            clf.fit(x_train, y_train)\n",
    "            predict = clf.predict(x_test)\n",
    "            predict_train = clf.predict(x_train)\n",
    "\n",
    "            total_predictions[feature_id, test_data_length:test_data_length+len(y_test)] = predict\n",
    "            total_train_predictions[feature_id, train_data_length:train_data_length+len(y_train)] = predict_train\n",
    "\n",
    "\n",
    "        train_gt[train_data_length:train_data_length+len(y_train)] = y_train\n",
    "        test_data_length+=len(y_test)\n",
    "        train_data_length+=len(y_train)\n",
    "\n",
    "\n",
    "    final_test_voting = np.zeros(len(final_dataset))\n",
    "    for i in range(len(final_dataset)):\n",
    "        counts = Counter(total_predictions[:,i])\n",
    "        vals = list(counts.values())\n",
    "        if len(vals) == 1:\n",
    "            final_test_voting[i] = list(counts.keys())[np.argmax(list(counts.values()))]\n",
    "        elif vals[0] == vals[1]:\n",
    "            final_test_voting[i] = np.random.choice(list(counts.keys()))\n",
    "        else:\n",
    "            final_test_voting[i] = list(counts.keys())[np.argmax(list(counts.values()))]\n",
    "\n",
    "    final_train_voting = np.zeros(170)\n",
    "    for i in range(170):\n",
    "        counts_train = Counter(total_train_predictions[:,i])\n",
    "        train_vals = list(counts_train.values())\n",
    "        if len(train_vals) == 1:\n",
    "            final_train_voting[i] = list(counts_train.keys())[np.argmax(list(counts_train.values()))]\n",
    "        elif train_vals[0] == train_vals[1]:\n",
    "            final_train_voting[i] = np.random.choice(list(counts_train.keys()))\n",
    "        else:\n",
    "            final_train_voting[i] = list(counts_train.keys())[np.argmax(list(counts_train.values()))]\n",
    "        \n",
    "    return total_predictions, final_test_voting, final_train_voting, train_gt, total_train_predictions\n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "for i in range(len(y_labels)):\n",
    "    print('-' * 100)\n",
    "    print('-' * 100)\n",
    "    print('label name:', y_labels[i])\n",
    "    print()\n",
    "    final_v = label_predictions(y_labels[i], corresponding_x_features[i], corresponding_datasets[i], corresponding_models[i])[1]\n",
    "    final_train_v = label_predictions(y_labels[i], corresponding_x_features[i], corresponding_datasets[i], corresponding_models[i])[2]\n",
    "    train_gt= label_predictions(y_labels[i], corresponding_x_features[i], corresponding_datasets[i], corresponding_models[i])[3]\n",
    "    # print('Final voting:', final_v)\n",
    "    gt = np.array(final_dataset_SE[final_dataset_SE.columns[len(x_feature_lst_SE)+1:]][y_labels[i]])\n",
    "    acc = accuracy_score(final_v, gt)\n",
    "    acc_train = accuracy_score(final_train_v, train_gt)\n",
    "\n",
    "    gt_dict = Counter(gt)\n",
    "    train_gt_dict = Counter(train_gt)\n",
    "\n",
    "    train_correct_count_1 = 0\n",
    "    train_correct_count_0 = 0\n",
    "    for j in range(len(train_gt)):\n",
    "        if train_gt[j] == final_train_v[j]:\n",
    "            if train_gt[j] == 1:\n",
    "                train_correct_count_1 += 1\n",
    "            else:\n",
    "                train_correct_count_0 += 1\n",
    "\n",
    "\n",
    "    test_correct_count_1 = 0\n",
    "    test_correct_count_0 = 0\n",
    "    for j in range(len(gt)):\n",
    "        if gt[j] == final_v[j]:\n",
    "            if gt[j] == 1:\n",
    "                test_correct_count_1 += 1\n",
    "            else:\n",
    "                test_correct_count_0 += 1\n",
    "\n",
    "\n",
    "    print('TRAIN - # of 0 and 1 of Ground Truth', '// 0:', train_gt_dict[0], '    1:', train_gt_dict[1])\n",
    "    print('TRAIN - # of 0 and 1 correctly predict', '// 0:', train_correct_count_0, '    1:', train_correct_count_1)\n",
    "    print('TRAIN - ', round(train_correct_count_0/train_gt_dict[0],2), '//', round(train_correct_count_1/train_gt_dict[1],2))\n",
    "    print()\n",
    "\n",
    "    print('TEST - # of 0 and 1 of Ground Truth', '// 0:', gt_dict[0], '    1:', gt_dict[1])\n",
    "    print('TEST - # of 0 and 1 correctly predict', '// 0:', test_correct_count_0, '    1:', test_correct_count_1)\n",
    "    print('TEST - ', round(test_correct_count_0/gt_dict[0],2), '//', round(test_correct_count_1/gt_dict[1],2))\n",
    "\n",
    "    if gt_dict[0] > gt_dict[1]:\n",
    "        print('BASELINE ACCURACY', round(train_gt_dict[0]/(train_gt_dict[0]+train_gt_dict[1]), 2))\n",
    "    else:\n",
    "        print('BASELINE ACCURACY', round(train_gt_dict[1]/(train_gt_dict[0]+train_gt_dict[1]), 2))\n",
    "\n",
    "    print('Total Train Accuracy:', round(acc_train,2))\n",
    "    print('Total Test Accuracy:', round(acc,2))\n",
    "\n",
    "    print()\n",
    "    print('Confusion Matrix - ', y_labels[i])\n",
    "    print(confusion_matrix(final_v, gt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8c1690602d89c3dd3260252f43217fb908ecd031a94bca6273f9620780a1d6c2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('comp0084')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
