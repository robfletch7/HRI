{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('final_dataset.csv')\n",
    "dataset = dataset.set_index('Unnamed: 0')\n",
    "drop_columns = ['eda_time','time', 'gender']\n",
    "dataset.drop(drop_columns, axis=1, inplace=True)\n",
    "dataset = dataset.rename(columns={\"perc_change\": \"eda_perc_change\", \"abs_change\": \"eda_abs_change\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JUNEGO~1\\AppData\\Local\\Temp/ipykernel_22092/904489153.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_dataset[final_dataset == -1] = 0\n",
      "C:\\Users\\junegoo94\\miniconda3\\envs\\comp0084\\lib\\site-packages\\pandas\\core\\frame.py:3718: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._where(-key, value, inplace=True)\n",
      "C:\\Users\\JUNEGO~1\\AppData\\Local\\Temp/ipykernel_22092/904489153.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_dataset['eda_perc_change'] = final_dataset['eda_perc_change']/100 +1\n"
     ]
    }
   ],
   "source": [
    "perc_columns = [col for col in dataset.columns if 'perc' in col]\n",
    "dataset_perc = df = dataset[dataset.columns.drop(list(dataset.filter(regex='abs')))]\n",
    "\n",
    "columns = ['eda_perc_change','perc_bpm','perc_rmssd','perc_sdsd','participantID', 'change_in_stressed', 'change_in_amused','change_in_engaged','change_in_frustrated']\n",
    "final_dataset = dataset_perc[columns]\n",
    "final_dataset[final_dataset == -1] = 0\n",
    "final_dataset['eda_perc_change'] = final_dataset['eda_perc_change']/100 +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_feature_lst = final_dataset.columns[:4]\n",
    "y_labels = ['change_in_stressed', 'change_in_amused','change_in_engaged','change_in_frustrated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['change_in_stressed',\n",
       " 'change_in_amused',\n",
       " 'change_in_engaged',\n",
       " 'change_in_frustrated']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC(kernel='linear')\n",
    "dt = DecisionTreeClassifier(random_state=0)\n",
    "rt = RandomForestClassifier(n_estimators = 10,max_depth=2, random_state=0,min_samples_leaf=1)\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "\n",
    "models_lst = [svm, dt, rt, knn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model selection\n",
    "label_feature_model = np.zeros((len(y_labels),len(x_feature_lst)))\n",
    "\n",
    "for label_id in range(len(y_labels)):\n",
    "    for feature_id in range(len(x_feature_lst)):\n",
    "        results_acc = []\n",
    "\n",
    "        for model in models_lst:\n",
    "            clf = model\n",
    "            participantIDs = np.arange(11)\n",
    "            # Start Cross-Validation\n",
    "            for i, a in enumerate(participantIDs):\n",
    "                train_ids = participantIDs[participantIDs!=i]\n",
    "                test_ids = participantIDs[participantIDs==i]\n",
    "                train_data = final_dataset.loc[final_dataset['participantID'].isin(train_ids)]\n",
    "                test_data = final_dataset.loc[final_dataset['participantID'].isin(test_ids)]\n",
    "\n",
    "\n",
    "                x_train = np.array(train_data[x_feature_lst[feature_id]].values).reshape(-1, 1)\n",
    "                y_train = np.array(train_data[y_labels[label_id]].values)\n",
    "                x_test = np.array(test_data[x_feature_lst[feature_id]].values).reshape(-1, 1)\n",
    "                y_test = np.array(test_data[y_labels[label_id]].values)\n",
    "\n",
    "                clf.fit(x_train, y_train)\n",
    "                predict = clf.predict(x_test)\n",
    "\n",
    "                if i == 0:\n",
    "                    predictions = predict\n",
    "                else:\n",
    "                    predictions = np.concatenate([predictions, predict])\n",
    "\n",
    "\n",
    "            results_acc.append(accuracy_score(predictions, final_dataset[y_labels[2]].values))\n",
    "\n",
    "        best_model_ind = np.argmax(results_acc)\n",
    "        label_feature_model[label_id, feature_id] = best_model_ind\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eda_perc_change</th>\n",
       "      <th>perc_bpm</th>\n",
       "      <th>perc_rmssd</th>\n",
       "      <th>perc_sdsd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>change_in_stressed</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>change_in_amused</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>change_in_engaged</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>change_in_frustrated</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      eda_perc_change  perc_bpm  perc_rmssd  perc_sdsd\n",
       "change_in_stressed                1.0       3.0         2.0        1.0\n",
       "change_in_amused                  0.0       3.0         1.0        1.0\n",
       "change_in_engaged                 0.0       3.0         2.0        2.0\n",
       "change_in_frustrated              0.0       0.0         0.0        1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_label_feature_model = pd.DataFrame(label_feature_model,\n",
    "                  index=y_labels, columns=x_feature_lst)\n",
    "\n",
    "pd_label_feature_model # 0.0 -> svm, 1.0 -> dt, 2.0 -> rf, 3.0 -> knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_predictions(y_label):\n",
    "    '''\n",
    "    - Description:\n",
    "        returns final voting predictions for one label (ex: change_in_stressed)\n",
    "    - returns:\n",
    "        total_predictions - > (selected models, prediction(data))\n",
    "        final_voting -> (1, voting prediction)\n",
    "    '''\n",
    "\n",
    "    total_predictions = np.zeros((len(x_feature_lst), len(final_dataset)))\n",
    "    # for label_id in range(len(y_labels)):\n",
    "    for feature_id in range(len(x_feature_lst)):\n",
    "        results_acc = []\n",
    "\n",
    "        model_ind = label_feature_model[0, feature_id]\n",
    "        clf = models_lst[int(model_ind)]\n",
    "        participantIDs = np.arange(11)\n",
    "\n",
    "        # Start Cross-Validation\n",
    "        for i, a in enumerate(participantIDs):\n",
    "            train_ids = participantIDs[participantIDs!=i]\n",
    "            test_ids = participantIDs[participantIDs==i]\n",
    "            train_data = final_dataset.loc[final_dataset['participantID'].isin(train_ids)]\n",
    "            test_data = final_dataset.loc[final_dataset['participantID'].isin(test_ids)]\n",
    "\n",
    "\n",
    "            x_train = np.array(train_data[x_feature_lst[feature_id]].values).reshape(-1, 1)\n",
    "            y_train = np.array(train_data[y_label].values)\n",
    "            x_test = np.array(test_data[x_feature_lst[feature_id]].values).reshape(-1, 1)\n",
    "            y_test = np.array(test_data[y_label].values)\n",
    "\n",
    "            clf.fit(x_train, y_train)\n",
    "            predict = clf.predict(x_test)\n",
    "\n",
    "            if i == 0:\n",
    "                predictions = predict\n",
    "            else:\n",
    "                predictions = np.concatenate([predictions, predict])\n",
    "\n",
    "        total_predictions[feature_id, :] = predictions\n",
    "\n",
    "    final_voting = np.zeros(len(final_dataset))\n",
    "    for i in range(len(final_dataset)):\n",
    "        counts = Counter(total_predictions[:,i])\n",
    "        final_voting[i] = list(counts.keys())[np.argmax(list(counts.values()))]\n",
    "        \n",
    "        \n",
    "    return total_predictions, final_voting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "label name change_in_stressed\n",
      "\n",
      "Final voting: [1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1.]\n",
      "Ground Truth: [1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1.]\n",
      "Accuracy: 0.5882352941176471\n",
      "--------------------\n",
      "label name change_in_amused\n",
      "\n",
      "Final voting: [1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1.]\n",
      "Ground Truth: [0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0.]\n",
      "Accuracy: 0.4117647058823529\n",
      "--------------------\n",
      "label name change_in_engaged\n",
      "\n",
      "Final voting: [0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      "Ground Truth: [0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1.]\n",
      "Accuracy: 0.6470588235294118\n",
      "--------------------\n",
      "label name change_in_frustrated\n",
      "\n",
      "Final voting: [1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1.]\n",
      "Ground Truth: [0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0.]\n",
      "Accuracy: 0.5294117647058824\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(y_labels)):\n",
    "    print('-' * 20)\n",
    "    print('label name', y_labels[i])\n",
    "    print()\n",
    "    final_v = label_predictions(y_labels[i])[1]\n",
    "    print('Final voting:', final_v)\n",
    "    gt = np.array(final_dataset[final_dataset.columns[5:]][y_labels[i]])\n",
    "    acc = accuracy_score(final_v, gt)\n",
    "    print('Ground Truth:', gt)\n",
    "    print('Accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8c1690602d89c3dd3260252f43217fb908ecd031a94bca6273f9620780a1d6c2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('comp0084')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
